{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5176b57-b1ea-4914-8d2d-c47ced66008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "standard_phrases = []\n",
    "with open('Standardised terms.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        standard_phrases.append(row[0])\n",
    "        \n",
    "print(standard_phrases)\n",
    "with open('sample_text.txt', 'r') as file:\n",
    "    input_text = file.read()\n",
    "    \n",
    "    \n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    cleaned_tokens = [[word.lower() for word in words if word.isalnum() and word.lower() not in stop_words] for words in word_tokens]\n",
    "    cleaned_sentences = [' '.join(words) for words in cleaned_tokens]\n",
    "    return cleaned_sentences\n",
    "\n",
    "input_sentences = preprocess_text(input_text)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_standard = tfidf_vectorizer.fit_transform(standard_phrases)\n",
    "tfidf_matrix_input = tfidf_vectorizer.transform(input_sentences)\n",
    "\n",
    "\n",
    "similarities = cosine_similarity(tfidf_matrix_input, tfidf_matrix_standard)\n",
    "\n",
    "\n",
    "threshold = 0.4  \n",
    "\n",
    "\n",
    "for i, sentence in enumerate(input_sentences):\n",
    "    similar_indices = [idx for idx, score in enumerate(similarities[i]) if score > threshold]\n",
    "    \n",
    "    if similar_indices:\n",
    "        print(f\"Original Sentence {i + 1}: {sentence}\")\n",
    "        for idx in similar_indices:\n",
    "            print(f\"Suggestion: Replace with '{standard_phrases[idx]}' (Similarity Score: {similarities[i][idx]:.2f})\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb7f6f35-9865-41bd-aabe-b0260b1014f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Optimal performance', 'Utilise resources', 'Enhance productivity', 'Conduct an analysis', 'Maintain a high standard', 'Implement best practices', 'Ensure compliance', 'Streamline operations', 'Foster innovation', 'Drive growth', 'Leverage synergies', 'Demonstrate leadership', 'Exercise due diligence', 'Maximize stakeholder value', 'Prioritise tasks', 'Facilitate collaboration', 'Monitor performance metrics', 'Execute strategies', 'Gauge effectiveness', 'Champion change']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nurse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nurse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "standard_phrases = []\n",
    "with open('Standardised terms.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        standard_phrases.append(row[0])\n",
    "        \n",
    "print(standard_phrases)\n",
    "with open('sample_text.txt', 'r') as file:\n",
    "    input_text = file.read()\n",
    "    \n",
    "    \n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    cleaned_tokens = [[word.lower() for word in words if word.isalnum() and word.lower() not in stop_words] for words in word_tokens]\n",
    "    cleaned_sentences = [' '.join(words) for words in cleaned_tokens]\n",
    "    return cleaned_sentences\n",
    "\n",
    "input_sentences = preprocess_text(input_text)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_standard = tfidf_vectorizer.fit_transform(standard_phrases)\n",
    "tfidf_matrix_input = tfidf_vectorizer.transform(input_sentences)\n",
    "\n",
    "\n",
    "similarities = cosine_similarity(tfidf_matrix_input, tfidf_matrix_standard)\n",
    "\n",
    "\n",
    "threshold = 0.4  \n",
    "\n",
    "\n",
    "for i, sentence in enumerate(input_sentences):\n",
    "    similar_indices = [idx for idx, score in enumerate(similarities[i]) if score > threshold]\n",
    "    \n",
    "    if similar_indices:\n",
    "        print(f\"Original Sentence {i + 1}: {sentence}\")\n",
    "        for idx in similar_indices:\n",
    "            print(f\"Suggestion: Replace with '{standard_phrases[idx]}' (Similarity Score: {similarities[i][idx]:.2f})\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "123376cf-67e6-43cb-8c1f-4285e2449280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence 3: came consensus need better terms performance\n",
      "Suggestion: Replace with 'Optimal performance' (Similarity Score: 0.66)\n",
      "Suggestion: Replace with 'Monitor performance metrics' (Similarity Score: 0.53)\n",
      "\n",
      "Original Sentence 7: aim efficient look ways creative daily tasks\n",
      "Suggestion: Replace with 'Prioritise tasks' (Similarity Score: 0.71)\n",
      "\n",
      "Original Sentence 8: growth essential future equally important building strong relationships team members\n",
      "Suggestion: Replace with 'Drive growth' (Similarity Score: 0.71)\n",
      "\n",
      "Original Sentence 9: reminder annual staff survey due next friday\n",
      "Suggestion: Replace with 'Exercise due diligence' (Similarity Score: 0.58)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    cleaned_tokens = [[word.lower() for word in words if word.isalnum() and word.lower() not in stop_words] for words in word_tokens]\n",
    "    cleaned_sentences = [' '.join(words) for words in cleaned_tokens]\n",
    "    return cleaned_sentences\n",
    "\n",
    "input_sentences = preprocess_text(input_text)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_standard = tfidf_vectorizer.fit_transform(standard_phrases)\n",
    "tfidf_matrix_input = tfidf_vectorizer.transform(input_sentences)\n",
    "\n",
    "\n",
    "similarities = cosine_similarity(tfidf_matrix_input, tfidf_matrix_standard)\n",
    "\n",
    "\n",
    "threshold = 0.4  \n",
    "\n",
    "\n",
    "for i, sentence in enumerate(input_sentences):\n",
    "    similar_indices = [idx for idx, score in enumerate(similarities[i]) if score > threshold]\n",
    "    \n",
    "    if similar_indices:\n",
    "        print(f\"Original Sentence {i + 1}: {sentence}\")\n",
    "        for idx in similar_indices:\n",
    "            print(f\"Suggestion: Replace with '{standard_phrases[idx]}' (Similarity Score: {similarities[i][idx]:.2f})\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207bc91-9feb-47f4-be68-da8b3dce6d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
